    # 减少acc 减少魔法数（人无法理解） 简单+贴切

    #
    # 思考：1 不加入acc规则 （loss和acc如何结合是个问题。。。）
            1.1 acc类似reward或者perplexity，其 排名/震荡程度/趋势 是有一定意义的。但是loss和acc如何结合成了问题。。。
            1.2 不加acc的规则显得较为单薄？（一共5种症状，其实还行）
           2 "魔法数"难以界定（基本都是底层指标，需要先验知识理解），非魔法数跨场景通用可能存在困难 "魔法效果"
           3 一些规则的超参数意义相同，数值其实也可以取一样的，是否合并？已取消


    # enable_cond: (global) global_cmp_num > min_cmp_num && global_loss_percent < 90%

    # EG: (step:half1)
    # eg_rule0: any(has_nan or has_inf)
    # eg_rule1: max(grad_abs_ave) > p_eg1 ||| (p_eg1:10)
    # eg_rule2: median(adjacent_quotient) > p_eg2 ||| (p_eg2:100) 改为median
    # eg_rule3: train_loss >= global_median_train_loss * p_eg3 ||| (p_eg3:5) 稍微改小

    # VG: (step:half1)
    # protect_top_train_loss: True
    # vg_rule1: median(grad_abs_ave) < p_vg1 ||| (p_vg1:1.e-7) 。。。魔法数且作用小，已去掉
    # vg_rule2: median(adjacent_quotient) < p_vg2 ||| (p_vg3:0.01) 逻辑修复，验证ok
    # vg_rule3: mean(abs_delta_train_loss) < train_loss[0] * p_vg3 ||| (p_vg3:0.001) 逻辑已修改！！！！！！!!!!!!!!!!!
    # vg_rule4: enough(cmp_num) && percent(global_median_grad_abs_ave) < p_vg4 ||| (p_vg4:0.1) 新加入相对，验证ok

    # DR: (step:all)
    # protect_top_train_loss: True
    # dr_rule1: median(rate0) < p_dr1 ||| (p_dr1:0.1) 已经改any为median且调小了p_dr1
    # dr_rule2: weighted_mean(rate0) > p_dr2 ||| (p_dr2:0.5) 。。。同质，已经取消
    # dr_rule3: enough(cmp_num) && percent(global_median_rate0) > p_dr3 ||| (p_dr3:0.9) 新加入相对，验证ok

    # SC: (step:half1)
    # protect_top_train_loss: True
    # sc_rule1: (acc[0]-acc[-1]) / acc[0] > p_sc1 ||| (p_sc1:0) 。。。同质acc混，已经取消
    # sc_rule2: (train_loss[-1]-train_loss[0]) / train_loss[0] > p_sc2 ||| (p_sc2:0) 已经改逻辑，只检测比初始还差的
    # sc_rule3: percentile(train_loss) > p_sc3 * 100 ||| (p_sc3:0.9) ！！！！！保留，也算相对比较，力度轻即可(0.9)

    # HO(heavy oscillation): (step:half2) (wd:0.25)
    # ho_rule1: std(acc[-wd:]) / mean(acc[-wd:]) > p_ho1 ||| (p_ho1:0) 。。。同质acc混，考虑取消
    # ho_rule2: MAE(train_loss[-wd:] - line(train_loss[-wd:])) > mean(train_loss[-wd:]) * p_ho2  ||| (p_ho2:0.01) 已经改逻辑，验证ok，魔法数

    # NMG(no more gain): (step:half2) (wd:0.25)
    # protect_top_train_loss: True
    # nmg_rule1: max(acc[-wd:]) != max(acc) 。。。同质acc混，考虑取消
    # nmg_rule2: min(train_loss[-wd:]) - min(train_loss) > min(train_loss) * p_nmg2 ||| (p_nmg2:0) 已经改逻辑，验证ok

    # 行文思路
    # abstract：
    # intro：偏里程碑，主要HPO和ETR，前任没做过程诊断，简单介绍诊断，总结诊断加入HPO，加注意
    # related：更细一些，偏体系，eg：HPO类别，AT规则
    # method：呼应注意
        开头：指标和训练效果图和分析（分布图），-》依据吧啦区分"坏实验"
        后面：介绍我们指标体系（包括症状及其判定标准）（树状分支图，梯度，激活，损失）及其特性
        实现：指标采集过程（代码怎么做）（Pytorch+流程图）（指标流过的路线）
    # experiment：
        intro：data+model+HPO+space
        time：图+表（1《-》1+1）
        explain（random+simulate）：1 rank图（说明负面效果并不差）2 指标分布图 3 消融实验（比例图+吧啦表格（eg节约时间））
    # discussion（weakness）：
        弱点+难点+挑战（上下文相关）：指标定义难 / 场景通用难 / gcgjv / 和BO相互影响(X+1) / 和其他ETR相互影响(R+1+1)
    # conclusion：（附带future）
    # 注意：不是combine，注意区别"坏"和"不好"

    1 保证实验
    2 各种画图 (缺失：时间图/特征分布图/效果分布图 ||| )
    2 各种表格 (缺失：时间表/节约表？/场景表？/。。。)
    3 intro + related

    画图内容细化
    1 时间图：wait
        目的：展示our和不同HPO的topN随时间变化 (our: R+1)
        分图：1 先分4场景(不同行) 2 再分topN(1,5,10)(不同列) 3 再分our和不同HPO(同图不同线)
        期望：期望our一直领先所有其他HPO,特别是在前期(3/6之前)
    2 效果分布图：ok
        目的：表明our训练诊断和最终效果有很大关系 (...目的有点类似rank图，形式不同：rank限定trial数量，效果分布图限定trial比例，过程都是simulate)
        形式：x验证集效果值|y个数或比率|s划分方法 (s: raw | our(healthy+NMG) | ill) (按照数量画柱子更清晰？)
        分图：4图对应4场景 3颜色对应三种划分方法
    3 特征分布图：ing easy
        目的：展示"好/坏"超参数的DNN底层特征分布存在差异（不需要线性相关和明确的分界线）
        形式：x特征值|y个数或比率|s划分方法|r划分比率默认10% (s包含验证集acc和loss，x包含梯度激活损失，场景和HPO无所谓，选一默认)-》难点：x分布诡异，柱子难分，考虑取对数
        分图：1 训练损失值x|验证正确率s 2 梯度均值x|正确率y 3 首步训练损失差值x|验证损失值s 4 梯度均值x|损失值s
        期望："好/坏"的分布显著不同，最好是好的更集中，坏的更分散
    4 rank图：。。。取消
        目的：表明our训练诊断和最终效果有很大关系(能做到"保留好，排除坏")
        分列：raw | our(healthy+NMG) | ill
        期望：our接近raw，ill远离raw
    5 pie图：ok
        目的：表明各个诊断规则的使用情况（half 看不到"误杀"情况）-》考虑 效果分布图+饼图缩小或合并 (或：仅用一个场景做细节展示,其他用表格)
        分列：1 (healthy | NMG | ill) 2 (EG | VG | DR | SC | HO | NMG) 3 (rules)
        期望：每个症状至少出现在两个场景，各个场景比例相同
    6 epoch图(训练迭代数图): ok
        目的：表明时间节省的效果 (限定时间内能尝试更多超参组合)
        形式：x验证集效果值|y个数或比率
        分列：original(raw) | our(healthy+NMG)
        期望：our低于original,一方面能减少验证集效果值不好的试验训练时间，另一方面对于验证集效果值好的试验训练时间影响不大



    表格内容细化
    1 时间表：wait
        目的：准确展示Our方法再不同场景下，效果随时间变化情况
        横行：1 先分效果指标(acc/loss) 2 再分具体场景(4)
        纵列：1 先分HPO和Our 2 再分topN(1,5,10)
    2 效率表：ing easy
        目的：展示Our方法在不同场景下，不同规则节约时间的比例（N epoch/trial）
        。。。
    3 场景表：ing easy
        目的：展示不同场景的配置（数据集，模型，超参数类型，空间大小）
        。。。


    核心思考：需要用什么图表展现Our的什么方面？ ！！！！！！！！
    前期提示：训练过程指标和最终效果是否相关？-》特征分布图 (分:x/y/s/r)
    中期展示：使用工具之后效果提升如何？-》时间效果图+时间效果表 (分:x/y/s/r)+rank效果值图(横坐标topK)
    后期解释：1 Our工具提升调参效果的直接原因？-》 提前停止"不健康"的实验，限定时间内能尝试更多参数组合-》训练迭代数图ok
            2 Our工具诊断结果跟最终效果的关系？-》效果分布图(分：ill/healthy)
            3 Our工具不同症状规则的贡献程度(消融)？-》饼状图+效率表（替代消融表(难simulate效果提升)）
            4 其他(选放讨论)  4.1 工具规则的鲁棒性？-》不同场景适配不同。。。(工具参数控制变量法，不同场景归一化画线)
                            4.2 X+1实验，不只Random，怕效果不好/泛化性说明
                            4.3 R+1+1实验，横向比较或增幅其他ETR


    下一步：
    1 改指标：加相对 ok
    1 画图：特征图easy 分布图ok 训练迭代数图ok

    注意：exchange "过拟合" Our无法分辨 Our效果就一般

    风险提示：
    HPO本身可能比random+our好。
    考虑X+1实验？或取最佳试验效果即可

    下一步：
    1 细化特征现象图
    2 风险排查估计
    3 讨论画图和规则
    4 论文写作


    细化特征现象图
    1 三张图展示三种类型的特征：
        1.1 早期的训练损失值x (train_loss) | 最终的验证集正确率y (validate_acc) -> cifar10cnn
        1.2 早期的梯度中值x (median_abs_grad) | 最终的验证集正确率y (validate_acc) -> cifar10lstm
        1.3 早期的激活覆盖率x (active_layer_ratio) | 最终的验证集损失值y  (validate_loss)-> traffic96aoto
        (early stage) ||| (last epoch)
        good: top10% | bad: bottom10%

    调整两图：
    1 迭代数图：蓝色红色柱子并列 ok
    2 特征分布图/效果指标分布图：柱子大小一致 ok
    3 转png为pdf？为了写作？...


    1 epoch图修改 纵坐标 Duration s


















